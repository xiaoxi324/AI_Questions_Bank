import os
import json
import re
from docx import Document
from docx.document import Document as _Document
from docx.oxml.text.paragraph import CT_P
from docx.oxml.table import CT_Tbl
from docx.table import _Cell, Table
from docx.text.paragraph import Paragraph


# ================== é…ç½® ==================
class Config:
    # è¾“å…¥æ–‡ä»¶å¤¹ï¼šå­˜æ”¾ docx çš„ç›®å½•
    INPUT_DIR = r"G:\KnowledgeBase\æ•´ç†å¥½çš„åŸå§‹æ–‡ä»¶"

    # è¾“å‡ºæ–‡ä»¶å¤¹ï¼šå­˜æ”¾ json çš„ç›®å½•
    OUTPUT_DIR = r"G:\KnowledgeBase\åˆ†è¯åæ•°æ®"


config = Config()


# ================== æ ¸å¿ƒå·¥å…·å‡½æ•° ==================

def iter_block_items(parent):
    """
    ç”Ÿæˆå™¨ï¼šæŒ‰æ–‡æ¡£é¡ºåºéå† docx ä¸­çš„æ‰€æœ‰å†…å®¹ï¼ˆåŒ…æ‹¬æ®µè½å’Œè¡¨æ ¼ï¼‰ã€‚
    """
    if isinstance(parent, _Document):
        parent_elm = parent.element.body
    elif isinstance(parent, _Cell):
        parent_elm = parent._tc
    else:
        raise ValueError("Unsupported parent type")

    for child in parent_elm.iterchildren():
        if isinstance(child, CT_P):
            yield Paragraph(child, parent)
        elif isinstance(child, CT_Tbl):
            yield Table(child, parent)


def table_to_markdown(table) -> str:
    """
    å°† docx è¡¨æ ¼å¯¹è±¡è½¬æ¢ä¸º Markdown å­—ç¬¦ä¸²
    """
    if not table.rows:
        return ""

    rows_content = []
    for row in table.rows:
        row_cells = []
        for cell in row.cells:
            # æ¸…æ´—å•å…ƒæ ¼å†…çš„æ¢è¡Œç¬¦
            cell_text = cell.text.strip().replace('\n', '<br>')
            row_cells.append(cell_text)
        rows_content.append(row_cells)

    if not rows_content:
        return ""

    lines = []
    # 1. è¡¨å¤´
    headers = rows_content[0]
    lines.append("| " + " | ".join(headers) + " |")
    # 2. åˆ†éš”çº¿
    lines.append("| " + " | ".join(["---"] * len(headers)) + " |")
    # 3. æ•°æ®è¡Œ
    if len(rows_content) > 1:
        for row in rows_content[1:]:
            while len(row) < len(headers):
                row.append("")
            row = row[:len(headers)]
            lines.append("| " + " | ".join(row) + " |")

    return "\n" + "\n".join(lines) + "\n"


def clean_text(text):
    """ç®€å•çš„æ–‡æœ¬æ¸…æ´—"""
    if not text:
        return ""
    return text.strip()


# ================== å¤„ç†é€»è¾‘ ==================

def process_annotated_docx(docx_path):
    """å¤„ç†æ ‡æ³¨å¥½çš„æ–‡æ¡£ï¼Œå‰”é™¤æ ‡é¢˜æœ¬èº«ï¼Œä¿ç•™è¡¨æ ¼"""
    try:
        doc = Document(docx_path)
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {docx_path}, é”™è¯¯: {e}")
        return []

    file_name = os.path.basename(docx_path)
    fragments = []

    # å®šä¹‰æœ€å¤§å±‚çº§
    MAX_LEVEL = 8

    # åˆå§‹åŒ–ä¸Šä¸‹æ–‡
    current_context = {
        "æ¥æºæ–‡ä»¶": file_name,
        "å®Œæ•´è·¯å¾„": "",
        "ç»„åˆæ ‡é¢˜": ""
    }
    for i in range(1, MAX_LEVEL + 1):
        current_context[f"L{i}"] = ""

    current_content = []

    def get_context_title():
        """ç”Ÿæˆé€šç”¨ç»„åˆæ ‡é¢˜ (å‘ä¸Šæ‰¾2å±‚)"""
        deepest_level = 0
        for i in range(MAX_LEVEL, 0, -1):
            if current_context[f"L{i}"]:
                deepest_level = i
                break
        if deepest_level == 0:
            return ""
        start_level = max(1, deepest_level - 2)
        title_parts = []
        for i in range(start_level, deepest_level + 1):
            val = current_context[f"L{i}"]
            if val:
                title_parts.append(val)
        return " - ".join(title_parts)

    def save_fragment():
        """ä¿å­˜å½“å‰ç‰‡æ®µ"""
        if current_content:
            content_text = "\n".join([txt for txt in current_content if txt.strip()])

            if content_text:
                fragment = current_context.copy()
                fragment["ç‰‡æ®µå†…å®¹"] = content_text
                fragment["å­—æ•°"] = len(content_text)

                # A. æ„å»ºå®Œæ•´è·¯å¾„
                path_items = []
                for i in range(1, MAX_LEVEL + 1):
                    val = fragment[f"L{i}"]
                    if val:
                        path_items.append(val)
                full_path_str = "/".join(path_items)
                fragment["å®Œæ•´è·¯å¾„"] = full_path_str

                # B. ç»„åˆæ ‡é¢˜
                fragment["ç»„åˆæ ‡é¢˜"] = get_context_title()

                # C. å‘é‡æ–‡æœ¬ (æ ¸å¿ƒä¿®æ”¹ï¼šå®Œæ•´è·¯å¾„ + çº¯å‡€å†…å®¹)
                # è¿™æ ·æ£€ç´¢æ—¶åŒ…å«æ ‡é¢˜è¯­ä¹‰ï¼Œä½†å±•ç¤ºæ—¶æ²¡æœ‰æ ‡é¢˜å¹²æ‰°
                fragment["å‘é‡æ–‡æœ¬"] = f"{full_path_str}ï¼š\n{content_text}"

                fragments.append(fragment)

            current_content.clear()

    print(f"ğŸš€ æ­£åœ¨åˆ‡åˆ†: {file_name} ...")

    for block in iter_block_items(doc):

        # --- æƒ…å†µ1: é‡åˆ°æ®µè½ ---
        if isinstance(block, Paragraph):
            text = clean_text(block.text)
            if not text:
                continue

            style = block.style.name
            is_heading = False
            level = 0

            # åˆ¤æ–­æ ‡é¢˜å±‚çº§
            match = re.match(r'^(Heading|æ ‡é¢˜)\s*([1-8])$', style, re.IGNORECASE)
            if match:
                level = int(match.group(2))
                is_heading = True
            else:
                try:
                    if 0 <= block.paragraph_format.outline_level <= 7:
                        level = block.paragraph_format.outline_level + 1
                        is_heading = True
                except:
                    pass

            if is_heading:
                # 1. é‡åˆ°æ–°æ ‡é¢˜ï¼Œå…ˆæŠŠã€ä¸Šä¸€æ®µã€‘çš„å†…å®¹å­˜ç›˜
                save_fragment()

                # 2. ã€æ ¸å¿ƒä¿®æ”¹ã€‘ä¸è¦æŠŠæ ‡é¢˜æœ¬èº«åŠ å…¥ current_content
                # current_content.append(text)  <-- è¿™ä¸€è¡Œåˆ æ‰äº†

                # 3. æ›´æ–°ä¸Šä¸‹æ–‡å±‚çº§ (æ ‡é¢˜åªå­˜åœ¨äº Metadata å’Œ è·¯å¾„ä¸­)
                if 1 <= level <= MAX_LEVEL:
                    current_context[f"L{level}"] = text
                    # æ¸…ç©ºå­å±‚çº§
                    for d in range(level + 1, MAX_LEVEL + 1):
                        current_context[f"L{d}"] = ""
            else:
                # æ™®é€šæ®µè½æ‰åŠ å…¥å†…å®¹
                current_content.append(text)

        # --- æƒ…å†µ2: é‡åˆ°è¡¨æ ¼ ---
        elif isinstance(block, Table):
            print(f"   Detected Table ({len(block.rows)} rows)")
            table_md = table_to_markdown(block)
            if table_md:
                current_content.append(table_md)

    # å¾ªç¯ç»“æŸåä¿å­˜æœ€åä¸€æ®µ
    save_fragment()
    return fragments


def batch_process_annotated_docs():
    """æ‰¹é‡å¤„ç†æŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰ docx"""
    input_dir = config.INPUT_DIR
    output_dir = config.OUTPUT_DIR

    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    if not os.path.exists(input_dir):
        print(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")
        return

    docx_files = [f for f in os.listdir(input_dir) if f.lower().endswith('.docx') and not f.startswith('~$')]

    if not docx_files:
        print("âš ï¸ ç›®å½•ä¸‹æ²¡æœ‰æ‰¾åˆ° .docx æ–‡ä»¶")
        return

    print(f"ğŸ“‚ å‘ç° {len(docx_files)} ä¸ªæ–‡æ¡£ï¼Œå‡†å¤‡å¤„ç†...")

    for doc_file in docx_files:
        full_input_path = os.path.join(input_dir, doc_file)

        data = process_annotated_docx(full_input_path)

        if data:
            json_name = os.path.splitext(doc_file)[0] + ".json"
            out_path = os.path.join(output_dir, json_name)

            with open(out_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)

            print(f"âœ… ä¿å­˜æˆåŠŸ ({len(data)} ç‰‡æ®µ): {json_name}")
        else:
            print(f"âš ï¸ è·³è¿‡ç©ºæ–‡ä»¶æˆ–è§£æå¤±è´¥: {doc_file}")


if __name__ == "__main__":
    batch_process_annotated_docs()