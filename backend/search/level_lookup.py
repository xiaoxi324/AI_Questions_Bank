import sys
import os
import math
import json
import chromadb

# === è·¯å¾„ä¿®å¤ ===
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(current_dir))
if project_root not in sys.path:
    sys.path.append(project_root)
# ======================

from typing import List, Dict, Any
from pydantic import BaseModel

# === å¯¼å…¥ä¾èµ– ===
from backend.knowledge.knowledge_tool import ChromaAdmin
from backend.tools.tools_call_ai import call_ai_emb
from backend.tools.tools_sql_connect import db
from config import config

EMBEDDING_DIM = getattr(config, "EMBEDDING_DIM", 4096)


# ==================== è¯·æ±‚æ¨¡å‹ ====================
class LevelLookupRequest(BaseModel):
    title_filter: str  # è¿‡æ»¤æ¡ä»¶
    search_content: str  # æ£€ç´¢å†…å®¹


# ==================== è¾…åŠ©å‡½æ•° ====================

def get_target_collections() -> List[str]:
    """
    [ç§»æ¤è‡ª search_tool.py] ä» SQL æ•°æ®åº“è·å–é…ç½®çš„é›†åˆåˆ—è¡¨
    """
    try:
        sql = "SELECT config_value FROM system_config WHERE config_key = 'search_collections'"
        res = db.execute_query(sql, fetch_one=True)
        if res and res['config_value']:
            return json.loads(res['config_value'])
    except Exception as e:
        print(f"âš ï¸ [LevelLookup] è¯»å–é›†åˆé…ç½®å¤±è´¥: {e}")

    return ["Pharmacopoeia_Official"]


def calculate_cosine_similarity(vec1: Any, vec2: Any) -> float:
    """
    ã€ä¿®å¤ç‰ˆã€‘è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
    ä¿®å¤äº† NumPy æ•°ç»„åœ¨ if åˆ¤æ–­ä¸­çš„ ambiguous é”™è¯¯
    """
    # 1. å®‰å…¨æ£€æŸ¥ï¼šæ˜¾å¼æ£€æŸ¥ None
    if vec1 is None or vec2 is None:
        return 0.0

    # 2. å®‰å…¨æ£€æŸ¥ï¼šæ£€æŸ¥é•¿åº¦ (æ— è®º list è¿˜æ˜¯ numpy array éƒ½æœ‰ len)
    if len(vec1) == 0 or len(vec2) == 0:
        return 0.0

    # 3. ç»´åº¦æ£€æŸ¥
    if len(vec1) != len(vec2):
        return 0.0

    # 4. è®¡ç®—é€»è¾‘
    try:
        dot_product = sum(a * b for a, b in zip(vec1, vec2))
        norm_a = math.sqrt(sum(a * a for a in vec1))
        norm_b = math.sqrt(sum(b * b for b in vec2))

        if norm_a == 0 or norm_b == 0:
            return 0.0
        return dot_product / (norm_a * norm_b)
    except Exception as e:
        print(f"âš ï¸ ç›¸ä¼¼åº¦è®¡ç®—æ•°å€¼é”™è¯¯: {e}")
        return 0.0


# ==================== æ ¸å¿ƒä¸šåŠ¡é€»è¾‘ ====================

def execute_level_lookup(req: LevelLookupRequest) -> Dict[str, Any]:
    """
    æ‰§è¡Œçº§æ ‡æ£€ç´¢
    """
    print(f"ğŸ” [LevelLookup] è¿‡æ»¤: '{req.title_filter}' | è¯­ä¹‰: '{req.search_content}'")

    client = ChromaAdmin.get_client()
    if not client:
        return {"status": "error", "msg": "å‘é‡æ•°æ®åº“æœªè¿æ¥"}

    # 1. åŠ¨æ€è·å–æ‰€æœ‰ç›®æ ‡é›†åˆ
    target_cols = get_target_collections()
    if not target_cols:
        return {"status": "error", "msg": "æœªé…ç½®ç›®æ ‡é›†åˆ"}

    # 2. é¢„å…ˆå‘é‡åŒ–æ£€ç´¢è¯
    query_emb = call_ai_emb(req.search_content, dimensions=EMBEDDING_DIM)
    if not query_emb:
        return {"status": "error", "msg": "AIå‘é‡åŒ–æœåŠ¡å¤±è´¥"}

    all_results = []
    total_candidates_count = 0

    # 3. éå†æ‰€æœ‰é›†åˆ
    for col_name in target_cols:
        try:
            col = client.get_collection(col_name)
            if not col: continue

            # --- é˜¶æ®µä¸€ï¼šåŸºäºæ ‡é¢˜/è·¯å¾„çš„ç¡¬è¿‡æ»¤ ---
            all_data = col.get(include=["metadatas"])
            all_ids = all_data['ids']
            all_metas = all_data['metadatas']

            local_candidate_ids = []
            filter_key = req.title_filter.strip().lower()

            for i, meta in enumerate(all_metas):
                if not meta: continue

                # åŒ¹é…é€»è¾‘
                is_hit = False
                combo = str(meta.get("ç»„åˆæ ‡é¢˜", "")).lower()
                path = str(meta.get("å®Œæ•´è·¯å¾„", "")).lower()

                if filter_key in combo or filter_key in path:
                    is_hit = True
                else:
                    for k in range(1, 9):
                        val = str(meta.get(f"L{k}", "")).lower()
                        if filter_key in val:
                            is_hit = True
                            break

                if is_hit:
                    local_candidate_ids.append(all_ids[i])

            count_local = len(local_candidate_ids)
            total_candidates_count += count_local

            if count_local == 0:
                continue

            # --- é˜¶æ®µäºŒï¼šè¯­ä¹‰é‡æ’ ---
            target_data = col.get(
                ids=local_candidate_ids,
                include=["embeddings", "documents", "metadatas"]
            )

            for i in range(len(target_data['ids'])):
                doc_emb = target_data['embeddings'][i]

                # [å…³é”®] è¿™é‡Œä¼ å…¥çš„ doc_emb å¯èƒ½æ˜¯ numpy æ•°ç»„ï¼Œç°åœ¨ calculate_cosine_similarity å·²å…¼å®¹
                score = calculate_cosine_similarity(query_emb, doc_emb)

                all_results.append({
                    "id": target_data['ids'][i],
                    "content": target_data['documents'][i],
                    "metadata": target_data['metadatas'][i],
                    "source_collection": col_name,
                    "score": score,
                    "score_percent": f"{score:.2%}"
                })

        except Exception as e:
            # è¿™é‡Œçš„ print æœ‰åŠ©äºæ•è·å…·ä½“æ˜¯å“ªä¸ªé›†åˆæŠ¥äº†ä»€ä¹ˆé”™
            print(f"âš ï¸ é›†åˆ [{col_name}] å¤„ç†å‡ºé”™: {e}")
            continue

    # 4. å…¨å±€æ’åº
    all_results.sort(key=lambda x: x['score'], reverse=True)

    # 5. æˆªå– Top 50
    final_top = all_results[:50]

    return {
        "status": "success",
        "total_candidates_scanned": total_candidates_count,
        "returned_count": len(final_top),
        "data": final_top
    }


# ==================== æµ‹è¯•å…¥å£ ====================
if __name__ == "__main__":
    # ç®€å•è‡ªæµ‹
    test_req = LevelLookupRequest(
        title_filter="æ„Ÿå†’",
        search_content="å‘çƒ§å¤´ç—›"
    )
    res = execute_level_lookup(test_req)
    print(f"\nâœ… æœ€ç»ˆçŠ¶æ€: {res['status']}")
    print(f"ğŸ“Š æ‰«æ: {res.get('total_candidates_scanned')} | è¿”å›: {res.get('returned_count')}")

    if res.get('data'):
        top = res['data'][0]
        print(f"ğŸ¥‡ TOP1: {top['metadata']['ç»„åˆæ ‡é¢˜']} | åˆ†æ•°: {top['score_percent']}")
    else:
        print("âš ï¸ æœªæ‰¾åˆ°åŒ¹é…ç»“æœ")