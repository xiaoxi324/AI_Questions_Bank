# backend/search/AI_search.py
import sys
import os
import re
import json
from openai import OpenAI
from typing import List, Dict, Any

# Ensure project root is in sys.path
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(current_dir))
if project_root not in sys.path:
    sys.path.append(project_root)

from config import config
from backend.search.search_tool import search_knowledge_structured


def segment_text(text: str) -> List[str]:
    """
    Segment the input text into lines.
    Empty lines are skipped.
    """
    lines = [line.strip() for line in text.split('\n') if line.strip()]
    return lines


def get_ai_client():
    ai_model = config.LOCAL_CHAT_MODEL
    client = OpenAI(base_url=config.LOCAL_OPENAI_URL_CHAT, api_key="lm-studio")
    if "kimi" in ai_model.lower():
        client = OpenAI(base_url=config.KIMI_API_URL, api_key=config.KIMI_API_KEY)
    elif "doubao" in ai_model.lower():
        client = OpenAI(base_url=config.VOLCENGINE_API_URL, api_key=config.VOLCENGINE_API_KEY)
    return client, ai_model


def compare_segment_with_knowledge(segment: str, knowledge_fragments: List[Dict]) -> Dict[str, Any]:
    """
    Use AI to compare the segment with retrieved knowledge fragments.
    """
    client, model = get_ai_client()

    # Construct knowledge context string
    knowledge_context = ""
    for i, frag in enumerate(knowledge_fragments):
        knowledge_context += f"ã€ç‰‡æ®µ{i + 1}ã€‘(æ¥æº: {frag['source']})\n{frag['content']}\n\n"

    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è¯å­¦æ–‡æ¡£å®¡æ ¸åŠ©æ‰‹ã€‚è¯·å¯¹æ¯”ã€å¾…å®¡æ ¸æ–‡æœ¬ã€‘ä¸ã€çŸ¥è¯†åº“ç‰‡æ®µã€‘ã€‚

    ã€å¾…å®¡æ ¸æ–‡æœ¬ã€‘
    {segment}

    ã€çŸ¥è¯†åº“ç‰‡æ®µã€‘
    {knowledge_context}

    è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ‡å‡†åˆ¤æ–­ä¸€è‡´æ€§çŠ¶æ€ï¼š

    1. **å®Œå…¨ä¸€è‡´** (fully_consistent): 
       - å¾…å®¡æ ¸æ–‡æœ¬çš„å†…å®¹ä¸çŸ¥è¯†åº“åŸæ–‡è¡¨è¿°é«˜åº¦å»åˆï¼Œå…³é”®è¯ã€æ•°æ®å®Œå…¨ä¸€è‡´ã€‚
       - å…è®¸æå…¶è½»å¾®çš„æ ¼å¼å·®å¼‚ï¼Œä½†æ ¸å¿ƒé™ˆè¿°å¿…é¡»æ˜¯åŸæ–‡çš„å¤è¿°ã€‚

    2. **è¯­ä¹‰ä¸€è‡´** (semantically_consistent): 
       - å¾…å®¡æ ¸æ–‡æœ¬çš„è¡¨è¿°æ–¹å¼ï¼ˆå¦‚å¥å¼ã€æ¦‚æ‹¬ç¨‹åº¦ï¼‰ä¸åŸæ–‡ä¸åŒï¼Œä½†è¡¨è¾¾çš„**æ ¸å¿ƒå«ä¹‰**æ˜¯å®Œå…¨æ­£ç¡®çš„ã€‚
       - **æ²¡æœ‰**äº‹å®æ€§é”™è¯¯ï¼Œåªæ˜¯å†™æ³•ä¸åŒã€‚è¿™æ˜¯ä¸€ä¸ªâ€œè­¦å‘Šâ€çº§åˆ«ï¼Œè¡¨ç¤ºé€šè¿‡ä½†éœ€æ³¨æ„æªè¾ã€‚

    3. **é”™è¯¯** (error): 
       - å¾…å®¡æ ¸æ–‡æœ¬ä¸çŸ¥è¯†åº“å†…å®¹**å†²çª**ã€**çŸ›ç›¾**ã€‚
       - æˆ–è€…å¾…å®¡æ ¸æ–‡æœ¬æåŠçš„å…³é”®æ•°æ®/äº‹å®åœ¨çŸ¥è¯†åº“ä¸­**å®Œå…¨æ‰¾ä¸åˆ°ä¾æ®**ã€‚

    è¯·ä»¥JSONæ ¼å¼è¾“å‡ºç»“æœï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
    {{
        "status": "fully_consistent", // æˆ– "semantically_consistent" æˆ– "error"
        "diff_description": "å·®å¼‚ç®€è¿°...",
        "suggestion": "ä¿®æ”¹å»ºè®®...", // å¦‚æœæ˜¯å®Œå…¨ä¸€è‡´ï¼Œå¯ç•™ç©º
        "basis_fragment_index": [1]
    }}
    åªè¾“å‡ºJSONï¼Œä¸è¦åŒ…å«å…¶ä»–å†…å®¹ã€‚
    """

    try:
        response = client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.1
        )
        content = response.choices[0].message.content
        # Simple cleanup for potential markdown code blocks
        content = re.sub(r'```json\s*', '', content)
        content = re.sub(r'```', '', content).strip()
        result = json.loads(content)
        return result
    except Exception as e:
        return {
            "is_consistent": False,
            "diff_description": f"AIå¤„ç†å‡ºé”™: {str(e)}",
            "suggestion": "è¯·äººå·¥æ ¸æŸ¥",
            "basis_fragment_index": []
        }


def process_text_comparison(text: str):
    """
    æµå¼å¤„ç†ï¼šæ¯å¤„ç†å®Œä¸€æ®µï¼Œå°± yield ä¸€æ¬¡ç»“æœ
    """
    segments = segment_text(text)

    for i, segment in enumerate(segments):
        # 1. æ£€ç´¢
        search_res = search_knowledge_structured(query_main=segment)
        top_fragments = search_res[:3] if search_res else []

        # 2. AI å¯¹æ¯”
        comparison = compare_segment_with_knowledge(segment, top_fragments)

        # 3. æ„é€ å•æ¡ç»“æœå¯¹è±¡
        result_item = {
            "index": i + 1,  # åŠ ä¸Šåºå·æ–¹ä¾¿å‰ç«¯æ’åº
            "segment_content": segment,
            "retrieved_fragments": top_fragments,
            "comparison_result": comparison
        }

        # 4. ã€å…³é”®ã€‘ä½¿ç”¨ yield é€æ­¥è¿”å›æ•°æ®ï¼Œå¹¶ç”¨æ¢è¡Œç¬¦åˆ†éš”ï¼ˆNDJSONæ ¼å¼ï¼‰
        # ensure_ascii=False ç¡®ä¿ä¸­æ–‡ä¸ä¹±ç 
        yield json.dumps(result_item, ensure_ascii=False) + "\n"


def test_comparison():
    test_text = "é˜¿è«è¥¿æ—ä¸»è¦ç”¨äºæ²»ç–—æ•æ„ŸèŒå¼•èµ·çš„æ„ŸæŸ“ã€‚å¯¹é’éœ‰ç´ è¿‡æ•è€…ç¦ç”¨ã€‚"
    print(f"ğŸ§ª æµ‹è¯•æ–‡æœ¬: {test_text}")
    res = process_text_comparison(test_text)
    print(json.dumps(res, indent=2, ensure_ascii=False))


if __name__ == "__main__":
    test_comparison()