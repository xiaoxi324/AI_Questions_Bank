import os
import sys
import chromadb
from typing import List, Dict

# === 1. ç¯å¢ƒè·¯å¾„ä¿®å¤ ===
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(current_dir))
if project_root not in sys.path:
    sys.path.append(project_root)

# å¯¼å…¥é…ç½®å’Œå·¥å…·
from config import config
from backend.tools.tools_sql_connect import db
from backend.tools.tools_call_ai import call_ai_emb

# === 2. é…ç½® ===
# æ•°æ®åº“è·¯å¾„ (ä¿æŒç”¨åŒä¸€ä¸ªæ•°æ®åº“æ–‡ä»¶å¤¹)
VECTOR_DB_PATH = getattr(config, "VECTOR_DB_PATH_MEDIC", "G:/KnowledgeBase/vectorizer_medic")
# æ–°é›†åˆåç§°
COLLECTION_NAME = "Case_Question"
# å‘é‡ç»´åº¦
EMBEDDING_DIM = getattr(config, "EMBEDDING_DIM", 4096)


# ==================== 3. æ ¸å¿ƒé€»è¾‘ ====================

def fetch_data_from_sql():
    """ä» MySQL è·å–æ‰€æœ‰æ¡ˆä¾‹é¢˜"""
    print("Output: ğŸ“¡ æ­£åœ¨ä» MySQL è¯»å–æ¡ˆä¾‹æ•°æ®...")
    sql = "SELECT * FROM case_question"
    try:
        # fetch_all=True å‡è®¾ä½ çš„å·¥å…·æ”¯æŒï¼Œå¦‚æœä¸æ”¯æŒè¯·è‡ªè¡Œè°ƒæ•´
        rows = db.execute_query(sql)
        print(f"âœ… è·å–åˆ° {len(rows)} æ¡æ•°æ®")
        return rows
    except Exception as e:
        print(f"âŒ æ•°æ®åº“è¯»å–å¤±è´¥: {e}")
        return []


def init_chroma():
    """åˆå§‹åŒ– ChromaDB å®¢æˆ·ç«¯"""
    if not os.path.exists(VECTOR_DB_PATH):
        os.makedirs(VECTOR_DB_PATH, exist_ok=True)

    client = chromadb.PersistentClient(path=VECTOR_DB_PATH)

    # è·å–æˆ–åˆ›å»ºé›†åˆ
    # metadata ç”¨äºæè¿°è¿™ä¸ªé›†åˆæ˜¯å¹²å˜›çš„
    collection = client.get_or_create_collection(
        name=COLLECTION_NAME,
        metadata={"description": "ä¸´åºŠæ¡ˆä¾‹åˆ†æé¢˜åº“ï¼šåŒ…å«æ¡ˆä¾‹èƒŒæ™¯ä¸é—®é¢˜"}
    )
    return client, collection


def process_and_import():
    """ä¸»æµç¨‹"""
    # 1. è·å–æ•°æ®
    rows = fetch_data_from_sql()
    if not rows:
        return

    # 2. åˆå§‹åŒ–å‘é‡åº“
    client, collection = init_chroma()
    print(f"ğŸ“‚ è¿æ¥å‘é‡åº“: {VECTOR_DB_PATH}")
    print(f"ğŸ“¦ ç›®æ ‡é›†åˆ: {COLLECTION_NAME}")

    # 3. å¾ªç¯å¤„ç†
    total = len(rows)
    success_count = 0

    print(f"ğŸš€ å¼€å§‹å‘é‡åŒ–å¹¶å­˜å…¥ (æ€»è®¡ {total} æ¡)...")

    for index, row in enumerate(rows):
        try:
            # === A. æ„é€ å‘é‡æ–‡æœ¬ ===
            # æ ¼å¼ï¼š[æ¡ˆä¾‹]... [é—®é¢˜]...
            # è¿™ç§ç»“æ„è®© AI æ£€ç´¢æ—¶æ—¢èƒ½åŒ¹é…ç—…æƒ…ï¼Œåˆèƒ½åŒ¹é…é—®é¢˜ç‚¹
            case_txt = row.get('case_content', '') or ""
            stem_txt = row.get('stem', '') or ""

            # å¦‚æœæ²¡æœ‰æ¡ˆä¾‹å†…å®¹ï¼Œåªå­˜é—®é¢˜ï¼›å¦‚æœæœ‰ï¼Œåˆ™ç»„åˆ
            if not case_txt:
                vector_text = f"ã€é—®é¢˜ã€‘{stem_txt}"
            else:
                vector_text = f"ã€æ¡ˆä¾‹ã€‘{case_txt}\nã€é—®é¢˜ã€‘{stem_txt}"

            # === B. æ„é€  Metadata ===
            # å­˜å…¥ä¸€äº›æ£€ç´¢å AI å¯èƒ½éœ€è¦çš„å…³é”®ä¿¡æ¯ï¼Œé¿å…å›æŸ¥ SQL
            # æ³¨æ„ï¼šMetadata çš„å€¼å¿…é¡»æ˜¯ str, int, float, bool
            meta = {
                "db_id": row['question_id'],  # æ•°æ®åº“ä¸»é”®
                "source_id": row.get('source', 'æœªçŸ¥'),  # åŸå§‹æ–‡ä»¶ä¸­çš„ ID (78xxxx)
                "answer": row.get('answer', ''),  # ç­”æ¡ˆ
                "type": "case_analysis"
            }

            # === C. å‘é‡åŒ– ===
            emb = call_ai_emb(vector_text)

            if emb:
                # === D. å†™å…¥ Chroma ===
                # ä½¿ç”¨ source_id ä½œä¸ºå‘é‡åº“çš„ä¸»é”® IDï¼Œæ–¹ä¾¿å»é‡
                # å¦‚æœ source ä¸ºç©ºï¼Œåˆ™ä½¿ç”¨ db_id
                unique_id = str(row.get('source')) if row.get('source') else f"db_{row['question_id']}"

                collection.upsert(
                    ids=[unique_id],
                    documents=[vector_text],
                    embeddings=[emb],
                    metadatas=[meta]
                )
                success_count += 1

                # æ‰“å°è¿›åº¦
                if success_count % 10 == 0:
                    print(f"   â³ è¿›åº¦: {success_count}/{total}")
            else:
                print(f"   âš ï¸ è·³è¿‡: ID {row['question_id']} å‘é‡åŒ–è¿”å›ç©º")

        except Exception as e:
            print(f"   âŒ å¤„ç†å‡ºé”™ (ID: {row.get('question_id')}): {e}")

    print("=" * 50)
    print(f"ğŸ‰ å…¥åº“å®Œæˆï¼æˆåŠŸ: {success_count} / æ€»æ•°: {total}")
    print(f"ğŸ“ˆ é›†åˆå½“å‰æ€»æ•°æ®é‡: {collection.count()}")


# ==================== 4. æ£€ç´¢æµ‹è¯• ====================
def test_search():
    print("\nğŸ” æ‰§è¡Œæ£€ç´¢æµ‹è¯•...")
    client = chromadb.PersistentClient(path=VECTOR_DB_PATH)
    col = client.get_collection(COLLECTION_NAME)

    # æ¨¡æ‹Ÿä¸€ä¸ªæ¨¡ç³Šçš„ç—…æƒ…æè¿°
    query = "æ‚£è€…é«˜è¡€å‹ï¼Œå‡ºç°å·¦ä¾§è‚¢ä½“æ— åŠ›ï¼Œæ€€ç–‘è„‘æ¢—"
    print(f"â“ æé—®: {query}")

    vec = call_ai_emb(query)
    results = col.query(query_embeddings=[vec], n_results=2)

    for i, doc in enumerate(results['documents'][0]):
        meta = results['metadatas'][0][i]
        print(f"\n--- ç»“æœ {i + 1} (ID: {results['ids'][0][i]}) ---")
        print(f"ğŸ“„ å†…å®¹: {doc[:100]}...")  # åªæ‰“å°å‰100å­—
        print(f"ğŸ·ï¸ ç­”æ¡ˆ: {meta['answer']}")


if __name__ == "__main__":
    # 1. æ‰§è¡Œå¯¼å…¥
    process_and_import()

    # 2. æµ‹è¯•ä¸€ä¸‹
    test_search()