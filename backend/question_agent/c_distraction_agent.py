import sys
import os
import json
from typing import List, Dict, Optional, Any

# === 1. è·¯å¾„ä¸ç¯å¢ƒé…ç½® ===
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(current_dir))
if project_root not in sys.path:
    sys.path.append(project_root)

from config import config

# === LangChain 1.0+ ç»„ä»¶ ===
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, ToolMessage
from langchain_core.tools import tool
from langchain.agents import create_agent
from langchain.agents.structured_output import ToolStrategy
from pydantic import BaseModel, Field

# [å…³é”®ä¿®æ­£] å¯¼å…¥å·¥å…·ç®± (æ–‡ä»¶ååº”ä¸º a_question_tool.py)
from backend.question_agent.a_question_tool import QuestionToolbox

# åˆå§‹åŒ–å·¥å…·ç®±
toolbox = QuestionToolbox()


# =================================================================
# ğŸ› ï¸ å®šä¹‰å¹²æ‰°é¡¹ä¸“å®¶ä¸“ç”¨å·¥å…·
# =================================================================

@tool
def search_competitor_knowledge(keyword: str) -> str:
    """
    [å·®å¼‚åŒ–æ£€ç´¢] ç”¨äºæŸ¥æ‰¾ä¸æ­£ç¡®ç­”æ¡ˆç›¸ä¼¼ã€æ˜“æ··æ·†çš„çŸ¥è¯†ç‚¹ã€‚
    ä¾‹å¦‚ï¼šå¦‚æœæ­£ç¡®ç­”æ¡ˆæ˜¯"é˜¿å¸åŒ¹æ—"ï¼Œä½ å¯ä»¥æœ"å¸ƒæ´›èŠ¬"ã€"å¯¹ä¹™é…°æ°¨åŸºé…š"æ¥å¯»æ‰¾å¹²æ‰°ç´ æã€‚
    è¾“å…¥ï¼šæ˜“æ··æ·†çš„å…³é”®è¯ã€‚
    """
    # print(f"   ğŸ˜ˆ [è®¾å‘æ£€ç´¢] æ­£åœ¨å¯»æ‰¾å¹²æ‰°ç´ æ: {keyword}")
    results = toolbox.search_knowledge(keyword, top_k=3)
    if not results:
        return "æœªæ‰¾åˆ°ç›¸å…³å¯¹æ¯”çŸ¥è¯†ï¼Œè¯·åŸºäºè¯å­¦å¸¸è¯†æ„å»ºå¹²æ‰°é¡¹ã€‚"
    return "\n\n".join(results)


# =================================================================
# ğŸ“‹ å®šä¹‰ç»“æ„åŒ–è¾“å‡º Schema
# =================================================================

class DistractorSchema(BaseModel):
    """å•ä¸ªå¹²æ‰°é¡¹ç»“æ„"""
    content: str = Field(description="å¹²æ‰°é¡¹çš„å†…å®¹")
    trap_analysis: str = Field(description="è®¾è®¡æ€è·¯ï¼šä¸ºä»€ä¹ˆè¿™ä¸ªé€‰é¡¹å…·æœ‰è¿·æƒ‘æ€§ï¼Ÿï¼ˆä¾‹å¦‚ï¼šå¼ å† ææˆ´ã€æ•°å€¼æ··æ·†ï¼‰")


class DistractionOutput(BaseModel):
    """å¹²æ‰°é¡¹ç”Ÿæˆç»“æœ"""
    distractors: List[DistractorSchema] = Field(description="ç”Ÿæˆçš„å¹²æ‰°é€‰é¡¹åˆ—è¡¨")
    analysis_overall: str = Field(description="é’ˆå¯¹æ•´é“é¢˜çš„è§£æï¼ˆè§£é‡Šæ­£ç¡®é¡¹ä¸ºä»€ä¹ˆå¯¹ï¼Œå¹²æ‰°é¡¹ä¸ºä»€ä¹ˆé”™ï¼‰")


# =================================================================
# ğŸ˜ˆ å¹²æ‰°é¡¹ä¸“å®¶ (Distraction Agent)
# =================================================================

class DistractionAgent:
    def __init__(self):
        print(f"ğŸ§  [DistractionAgent] åˆå§‹åŒ–æ¨¡å‹: {config.LOCAL_CHAT_MODEL} (è®¾å‘æ¨¡å¼)")

        self.llm = ChatOpenAI(
            base_url=config.LOCAL_OPENAI_URL_CHAT,
            api_key="noneed",
            model=config.LOCAL_CHAT_MODEL,
            temperature=0.8,  # å¹²æ‰°é¡¹éœ€è¦æ›´é«˜çš„åˆ›é€ åŠ›æ¥"ç¼–é€ "åˆç†çš„é”™è¯¯
        )

        self.tools = [search_competitor_knowledge]

    def _build_system_prompt(self, context: Dict) -> str:
        """
        æ„å»ºâ€œè®¾å‘â€ä¸“ç”¨ Prompt
        """
        topic = context.get('topic', 'æœªçŸ¥')
        stem = context.get('stem', '')
        correct_options = context.get('correct_options', [])
        target_count = context.get('distractor_count', 3)  # éœ€è¦ç”Ÿæˆçš„å¹²æ‰°é¡¹æ•°é‡

        prompt = f"""ä½ æ˜¯ä¸€åã€å›½å®¶æ‰§ä¸šè¯å¸ˆèµ„æ ¼è€ƒè¯•ã€‘çš„å‘½é¢˜ç»„ä¸“å®¶ï¼Œä¸“é—¨è´Ÿè´£**ç¼–å†™å¹²æ‰°é€‰é¡¹ï¼ˆDistractorsï¼‰**ã€‚
ä½ çš„ç›®æ ‡æ˜¯è®¾è®¡å‡º{target_count}ä¸ª**ä¼¼æ˜¯è€Œé**ã€å…·æœ‰é«˜è¿·æƒ‘æ€§çš„é”™è¯¯é€‰é¡¹ï¼Œè€ƒå¯Ÿè€ƒç”Ÿå¯¹çŸ¥è¯†ç‚¹çš„ç²¾ç¡®æŒæ¡ç¨‹åº¦ã€‚

### 1. é¢˜ç›®ä¿¡æ¯
- **æ ¸å¿ƒè€ƒç‚¹**ï¼š{topic}
- **é¢˜å¹²**ï¼š{stem}
- **æ­£ç¡®ç­”æ¡ˆ**ï¼š{json.dumps(correct_options, ensure_ascii=False)}

### 2. å¹²æ‰°é¡¹è®¾è®¡ç­–ç•¥ï¼ˆå¿…é¡»æ‰§è¡Œï¼‰
ä¸è¦å‡­ç©ºæé€ ï¼Œè¯·è°ƒç”¨ `search_competitor_knowledge` å·¥å…·å»æ£€ç´¢**åŒç±»è¯ç‰©**æˆ–**æ˜“æ··æ·†æ¦‚å¿µ**çš„çœŸå®å±æ€§ï¼Œç„¶åå°†å…¶ä½œä¸ºå¹²æ‰°é¡¹ã€‚
æ¨èç­–ç•¥ï¼š
1. **å¼ å† ææˆ´**ï¼šæœç´¢åŒç±»è¯ç‰©çš„ç‰¹æ€§ï¼Œç§»èŠ±æ¥æœ¨ã€‚ä¾‹å¦‚ï¼šè€ƒ"é˜¿å¸åŒ¹æ—"ï¼Œå»æœ"å¯¹ä¹™é…°æ°¨åŸºé…š"çš„å‰¯ä½œç”¨ä½œä¸ºå¹²æ‰°é¡¹ã€‚
2. **é€»è¾‘åè½¬**ï¼šå°†"é€‚åº”ç—‡"å†™æˆ"ç¦å¿Œç—‡"ï¼Œå°†"æŠ‘åˆ¶"å†™æˆ"ä¿ƒè¿›"ã€‚
3. **ç¨‹åº¦åå·®**ï¼šå°†"æ…ç”¨"å†™æˆ"ç¦ç”¨"ï¼Œå°†"å¸¸è§"å†™æˆ"ç½•è§"ã€‚
4. **æ•°å€¼æ··æ·†**ï¼šå¦‚æœæ¶‰åŠå‰‚é‡ï¼Œæœç´¢è¯¥è¯ç‰©çš„å…¶ä»–å‰‚å‹ç”¨æ³•è¿›è¡Œæ··æ·†ã€‚

### 3. å·¥ä½œæµç¨‹
1. **åˆ†æ**ï¼šåˆ†ææ­£ç¡®ç­”æ¡ˆçš„ç‰¹å¾ï¼Œç¡®å®šæ˜“æ··æ·†å¯¹è±¡ï¼ˆç«å“è¯ç‰©ï¼‰ã€‚
2. **æ£€ç´¢**ï¼šè°ƒç”¨å·¥å…·æœç´¢æ˜“æ··æ·†å¯¹è±¡çš„å±æ€§ã€‚
3. **ç”Ÿæˆ**ï¼šç¼–å†™ {target_count} ä¸ªå¹²æ‰°é€‰é¡¹ï¼Œå¹¶ä¸ºæ¯ä¸ªé€‰é¡¹æ³¨æ˜è®¾è®¡æ€è·¯ã€‚
4. **è§£æ**ï¼šæœ€åç¼–å†™ä¸€æ®µå®Œæ•´çš„è¯•é¢˜è§£æï¼Œè§£é‡Šæ­£ç¡®é¡¹å¹¶æŒ‡å‡ºå¹²æ‰°é¡¹çš„é”™è¯¯ä¹‹å¤„ã€‚

### 4. è¾“å‡ºæ ¼å¼
è¯·è¾“å‡ºä¸¥æ ¼çš„ JSON æ ¼å¼ã€‚
"""
        return prompt

    def generate_stream(self, context: Dict):
        """
        æµå¼ç”Ÿæˆå¹²æ‰°é¡¹
        """
        system_prompt = self._build_system_prompt(context)
        user_input = "è¯·å¼€å§‹ç¼–å†™å¹²æ‰°é€‰é¡¹ã€‚"

        # åˆ›å»º Agent
        agent = create_agent(
            model=self.llm,
            tools=self.tools,
            system_prompt=system_prompt,
            response_format=ToolStrategy(DistractionOutput)
        )

        print(f"ğŸ˜ˆ [Agent] å¼€å§‹è®¾å‘: {context.get('topic')}")

        processed_ids = set()

        try:
            for event in agent.stream({"messages": [HumanMessage(content=user_input)]}, stream_mode="values"):

                messages = event.get("messages", [])
                if not messages: continue
                latest_msg = messages[-1]

                if hasattr(latest_msg, 'id') and latest_msg.id in processed_ids:
                    continue
                if hasattr(latest_msg, 'id'):
                    processed_ids.add(latest_msg.id)

                # 1. æ€è€ƒä¸å·¥å…·è°ƒç”¨
                if isinstance(latest_msg, AIMessage):
                    if latest_msg.tool_calls:
                        for tc in latest_msg.tool_calls:
                            yield {"type": "process",
                                   "content": f"\nğŸ§  **Agent æ€è€ƒ**: æ‰¾ç‚¹å¹²æ‰°ç´ æï¼ŒæŸ¥è¯¢ `{tc['name']}`\n"}
                            yield {"type": "process",
                                   "content": f"   ğŸ‘‰ å‚æ•°: {json.dumps(tc['args'], ensure_ascii=False)}\n"}
                    elif latest_msg.content:
                        if not (latest_msg.content.strip().startswith("{") and "distractors" in latest_msg.content):
                            yield {"type": "process", "content": f"ğŸ’­ **Agent**: {latest_msg.content}\n"}

                # 2. å·¥å…·è¿”å›
                elif isinstance(latest_msg, ToolMessage):
                    content_preview = latest_msg.content[:100].replace('\n', ' ') + "..."
                    yield {"type": "process", "content": f"ğŸ“š **æ··æ·†çŸ¥è¯†è¿”å›**: {content_preview}\n"}

            # 3. æœ€ç»ˆç»“æœ
            if "structured_response" in event:
                final_data = event["structured_response"]

                # è½¬æ¢ä¸º JSON å­—ç¬¦ä¸²
                if hasattr(final_data, 'model_dump_json'):
                    json_str = final_data.model_dump_json(indent=2, ensure_ascii=False)
                else:
                    json_str = final_data.json(indent=2, ensure_ascii=False)

                # å…³é”®ï¼šæ ‡è®°ä¸º final_json_stringï¼Œä¾› z_common.py æ•è·
                yield {"type": "final_json_string", "content": json_str}

        except Exception as e:
            yield {"type": "error", "content": f"\nâŒ **å‘ç”Ÿé”™è¯¯**: {str(e)}\n"}
            import traceback
            traceback.print_exc()


# ==================== å•å…ƒæµ‹è¯• ====================
if __name__ == "__main__":
    agent = DistractionAgent()

    # æ¨¡æ‹Ÿä» b_question_agent ä¼ æ¥çš„æ•°æ®
    input_context = {
        "topic": "é˜¿å¸åŒ¹æ—",
        "stem": "æ‚£è€…å¥³æ€§ï¼Œ58å²ï¼Œå› å…³èŠ‚ç–¼ç—›é•¿æœŸæœç”¨æ­¢ç—›è¯ï¼Œè¿‘æœŸå‡ºç°é»‘ä¾¿ã€‚å…³äºè¯¥è¯ç‰©çš„ä½œç”¨æœºåˆ¶ï¼Œå™è¿°æ­£ç¡®çš„æ˜¯",
        "correct_options": ["ä¸å¯é€†æŠ‘åˆ¶ç¯æ°§é…¶ï¼Œå‡å°‘è¡€æ “ç´ A2çš„åˆæˆ"],
        "distractor_count": 4  # éœ€è¦è¡¥å…¨4ä¸ªå¹²æ‰°é¡¹
    }

    print("-------------- å¼€å§‹æµå¼æµ‹è¯• --------------")
    for chunk in agent.generate_stream(input_context):
        if chunk.get("type") == "process":
            print(chunk["content"], end="")
        elif chunk.get("type") == "final_json_string":
            print("\nâœ… **å¹²æ‰°é¡¹ç”Ÿæˆå®Œæˆ**:")
            print(chunk["content"])