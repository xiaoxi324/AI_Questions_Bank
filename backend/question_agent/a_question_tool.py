import sys
import os
import json
import chromadb
import threading
from typing import List, Dict, Any, Union

# === 1. è·¯å¾„ä¸ç¯å¢ƒé…ç½® ===
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(current_dir))
if project_root not in sys.path:
    sys.path.append(project_root)

# å¯¼å…¥é…ç½®å’Œå·¥å…·
from config import config
from backend.tools.tools_call_ai import call_ai_emb
from backend.tools.tools_sql_connect import db

# [æ–°å¢] å¯¼å…¥å…¨å±€ä¸Šä¸‹æ–‡å˜é‡
from backend.tools.global_context import log_queue_ctx

# === 2. åŸºç¡€é…ç½® ===
DB_PATH = getattr(config, "VECTOR_DB_PATH_MEDIC", "G:/KnowledgeBase/vectorizer_medic")
EMBEDDING_DIM = getattr(config, "EMBEDDING_DIM", 4096)
CASE_COLLECTION_NAME = "Case_Question"


class QuestionToolbox:
    def __init__(self):
        self.client = None
        self._init_chroma()
        self.lock = threading.Lock()

    def _init_chroma(self):
        if not os.path.exists(DB_PATH):
            # print(f"âŒ [Toolbox] å‘é‡åº“è·¯å¾„ä¸å­˜åœ¨: {DB_PATH}")
            return
        try:
            self.client = chromadb.PersistentClient(path=DB_PATH)
        except Exception as e:
            print(f"âŒ [Toolbox] Chromaè¿æ¥å¤±è´¥: {e}")

    def _get_active_knowledge_collections(self) -> List[str]:
        """ä»MySQLè¯»å–é…ç½®çš„çŸ¥è¯†åº“åˆ—è¡¨"""
        default = ["Pharmacopoeia_Official"]
        try:
            sql = "SELECT config_value FROM system_config WHERE config_key = 'search_collections'"
            res = db.execute_query(sql, fetch_one=True)
            if res and res['config_value']:
                cols = json.loads(res['config_value'])
                if isinstance(cols, list) and cols:
                    return cols
        except:
            pass
        return default

    # =================================================================
    # ğŸ” è¾…åŠ©å‡½æ•°ï¼šå‘å…¨å±€ä¸Šä¸‹æ–‡æ¨é€æ—¥å¿—
    # =================================================================
    def _push_snippet_to_context(self, title: str, content: str, score: float):
        """
        å°è¯•å°†æ£€ç´¢ç‰‡æ®µæ¨é€åˆ°å½“å‰ä¸Šä¸‹æ–‡çš„æ—¥å¿—é˜Ÿåˆ—ä¸­
        """
        q = log_queue_ctx.get()  # è·å–å½“å‰ä¸Šä¸‹æ–‡ä¸­çš„é˜Ÿåˆ—
        if q:
            # æ„é€ ç¬¦åˆå‰ç«¯åè®®çš„æ•°æ®åŒ… type: snippet
            log_data = {
                "type": "snippet",
                "content": f"ğŸ“Œ **{title}** (ç›¸ä¼¼åº¦: {score:.4f})\n{content}\n{'-' * 40}\n"
            }
            # æ”¾å…¥é˜Ÿåˆ—ï¼Œéé˜»å¡
            q.put(log_data)
            print(f"\n[SNIPPET PUSHED] {title}")

    # =================================================================
    # ğŸ› ï¸ å·¥å…· 1: çŸ¥è¯†æ£€ç´¢
    # =================================================================
    def search_knowledge(self, query: str, top_k: int = 5) -> List[str]:
        if not self.client: return []

        with self.lock:
            vec = call_ai_emb(query, dimensions=EMBEDDING_DIM)
        if not vec: return []

        target_cols = self._get_active_knowledge_collections()
        all_results = []

        for col_name in target_cols:
            try:
                col = self.client.get_collection(col_name)
                res = col.query(query_embeddings=[vec], n_results=top_k,
                                include=["documents", "metadatas", "distances"])
                if res['documents'] and res['documents'][0]:
                    for i in range(len(res['documents'][0])):
                        score = 1 - res['distances'][0][i]
                        item = {
                            "score": score,
                            "content": res['documents'][0][i],
                            "metadata": res['metadatas'][0][i],
                            "collection": col_name
                        }
                        all_results.append(item)
            except:
                continue

        all_results.sort(key=lambda x: x['score'], reverse=True)
        final_list = all_results[:top_k]

        formatted_output = []

        # ğŸš€ [æ¨é€æ—¥å¿—]
        q = log_queue_ctx.get()
        if q: q.put({"type": "snippet", "content": f"\nğŸ” **æ­£åœ¨æ£€ç´¢çŸ¥è¯†**: {query}\n"})

        for i, item in enumerate(final_list):
            source = item['metadata'].get('ç»„åˆæ ‡é¢˜', item['metadata'].get('æ¥æºæ–‡ä»¶', 'æœªçŸ¥æ¥æº'))
            content_full = item['content'].strip()

            self._push_snippet_to_context(f"çŸ¥è¯†æ¥æº: {source}", content_full, item['score'])

            text_block = f"ã€æ¥æºï¼š{source}ã€‘\n{content_full}"
            formatted_output.append(text_block)

        return formatted_output

    # =================================================================
    # ğŸ› ï¸ å·¥å…· 2: æ¡ˆä¾‹æ£€ç´¢
    # =================================================================
    def search_similar_cases(self, query: str, top_k: int = 3) -> List[Dict]:
        if not self.client: return []

        with self.lock:
            vec = call_ai_emb(query, dimensions=EMBEDDING_DIM)
        if not vec: return []

        try:
            col = self.client.get_collection(CASE_COLLECTION_NAME)
            res = col.query(query_embeddings=[vec], n_results=top_k, include=["documents", "metadatas", "distances"])
        except:
            return []

        formatted_cases = []

        # ğŸš€ [æ¨é€æ—¥å¿—]
        q = log_queue_ctx.get()
        if q: q.put({"type": "snippet", "content": f"\nğŸ’Š **æ­£åœ¨æ£€ç´¢æ¡ˆä¾‹**: {query}\n"})

        if res['documents'] and res['documents'][0]:
            for i in range(len(res['documents'][0])):
                content_full = res['documents'][0][i].strip()
                meta = res['metadatas'][0][i]
                score = 1 - res['distances'][0][i]

                db_ids_str = str(meta.get('db_ids', ''))
                id_list = db_ids_str.split(',') if db_ids_str else []

                self._push_snippet_to_context(f"å‚è€ƒæ¡ˆä¾‹ (ID:{db_ids_str})", content_full, score)

                case_obj = {
                    "content": content_full,
                    "question_ids": id_list,
                    "score": score
                }
                formatted_cases.append(case_obj)

        return formatted_cases

    # =================================================================
    # ğŸ› ï¸ å·¥å…· 3: é¢˜ç›®è¯¦æƒ…æ£€ç´¢ (å·²ä¿®æ­£æ”¯æŒ A-L)
    # =================================================================
    def get_full_question_detail(self, question_id: Union[str, int]) -> Dict:
        """
        [å·¥å…·3] æ ¹æ® MySQL ID è·å–é¢˜ç›®æœ€è¯¦ç»†çš„ç»“æ„åŒ–æ•°æ®
        """
        if not question_id: return {}

        sql = """
        SELECT * FROM case_question WHERE question_id = %s
        """
        try:
            row = db.execute_query(sql, (question_id,), fetch_one=True)
            if row:
                options = {}
                # âœ… [ä¿®æ­£] æ‰©å±•åˆ° 12 ä¸ªé€‰é¡¹ (A - L)
                full_options = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l']
                for k in full_options:
                    key = f'option_{k}'
                    if row.get(key):
                        options[k.upper()] = row[key]

                return {
                    "id": row['question_id'],
                    "type": row['question_type'],
                    "case": row['case_content'],
                    "stem": row['stem'],
                    "options": options,
                    "answer": row['answer'],
                    "analysis": row['analysis']
                }
        except Exception as e:
            print(f"âŒ SQLæŸ¥è¯¢å¤±è´¥: {e}")

        return {}